---
title: "[NIPA]AI+ì›¹ê°œë°œ ì·¨ì—…ìº í”„ SWì‹¬í™” 7ì£¼ì°¨ 5íšŒ"
excerpt: "ë°ì¼ë¦¬ í•™ìŠµì¼ì§€"

categories:
  - Categories2
tags:
  - [ì •ë³´í†µì‹ ì‚°ì—…ì§„í¥ì›, NIPA, AIêµìœ¡, í”„ë¡œì íŠ¸, ìœ ë°ë¯¸, ITê°œë°œìº í”„, ê°œë°œìë¶€íŠ¸ìº í”„, í”„ë¡ íŠ¸ì—”ë“œ, ë°±ì—”ë“œ, AIì›¹ê°œë°œì·¨ì—…ìº í”„, ì·¨ì—…ìº í”„, ê°œë°œì·¨ì—…ìº í”„]

permalink: /categories2/post-name-here-21/

toc: true
toc_sticky: true

date: 2023-09-01
last_modified_at: 2023-09-01
---

## ğŸ¦¥ ë³¸ë¬¸



```python
## íŒ¨ì…˜ MNIST


ì²« ë²ˆì§¸ ì¤„ì€ tensorflow ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ keras ëª¨ë“ˆì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

ë‘ ë²ˆì§¸ ì¤„ì€ keras.datasets ëª¨ë“ˆì˜ load_data() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ Fashion-MNIST ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

load_data() í•¨ìˆ˜ëŠ” ë‘ ê°œì˜ íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤. (train_input, train_target) íŠœí”Œì€ í›ˆë ¨ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ì„ í¬í•¨í•˜ê³ , (test_input, test_target) íŠœí”Œì€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ì„ í¬í•¨í•©ë‹ˆë‹¤.

from tensorflow import keras

(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()


ë°ì´í„°ì˜ ëª¨ì–‘ì€ ë‹¤ìŒê³¼ ê°™ì€ ì„¸ ê°€ì§€ ìš”ì†Œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

ìƒ˜í”Œì˜ ê°œìˆ˜,
íŠ¹ì„±ì˜ ê°œìˆ˜,
ì±„ë„ì˜ ê°œìˆ˜
* ì´ ê²½ìš°, í›ˆë ¨ ì´ë¯¸ì§€ì˜ ëª¨ì–‘ì€ (60000, 28, 28)ì…ë‹ˆë‹¤. ì´ëŠ” 60,000ê°œì˜ ìƒ˜í”Œì´ ìˆê³ , ê° ìƒ˜í”Œì€ 28x28 í”½ì…€ì˜ í‘ë°± ì´ë¯¸ì§€ë¼ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. í›ˆë ¨ ë ˆì´ë¸”ì˜ ëª¨ì–‘ì€ (60000,)ì…ë‹ˆë‹¤. ì´ëŠ” 60,000ê°œì˜ ë ˆì´ë¸”ì´ ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ëª¨ì–‘ì€ (10000, 28, 28)ì…ë‹ˆë‹¤. ì´ëŠ” 10,000ê°œì˜ ìƒ˜í”Œì´ ìˆê³ , ê° ìƒ˜í”Œì€ 28x28 í”½ì…€ì˜ í‘ë°± ì´ë¯¸ì§€ë¼ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”ì˜ ëª¨ì–‘ì€ (10000,)ì…ë‹ˆë‹¤. ì´ëŠ” 10,000ê°œì˜ ë ˆì´ë¸”ì´ ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

print(train_input.shape, train_target.shape)

print(test_input.shape, test_target.shape)

import matplotlib.pyplot as plt
# 10ê°œì˜ subplotì„ ìƒì„±í•©ë‹ˆë‹¤.
fig, axs = plt.subplots(1, 10, figsize=(10,10))

# í›ˆë ¨ ì´ë¯¸ì§€ì˜ ì²« ë²ˆì§¸ 10ê°œë¥¼ subplotì— í‘œì‹œí•©ë‹ˆë‹¤.
for i in range(10):
  axs[i].imshow(train_input[i], cmap='gray_r')
  axs[i].axis('off')

# ê·¸ë˜í”„ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
plt.show()

print([train_target[i] for i in range(10)])
#  Fashion-MNIST ë°ì´í„° ì„¸íŠ¸ì˜ í›ˆë ¨ ë ˆì´ë¸”ì˜ ì²« ë²ˆì§¸ 10ê°œë¥¼ ì¶œë ¥

ì´ ì½”ë“œëŠ” NumPyì˜ unique() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ Fashion-MNIST ë°ì´í„° ì„¸íŠ¸ì˜ í›ˆë ¨ ë ˆì´ë¸”ì˜ ê³ ìœ í•œ ê°’ê³¼ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

np.unique() í•¨ìˆ˜ëŠ” ì…ë ¥ ë°°ì—´ì—ì„œ ê³ ìœ í•œ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. return_counts=True ë§¤ê°œë³€ìˆ˜ë¥¼ ì§€ì •í•˜ë©´ ê° ê³ ìœ í•œ ê°’ì— ëŒ€í•œ ê°œìˆ˜ë¥¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤.

ì´ ì½”ë“œëŠ” Fashion-MNIST ë°ì´í„° ì„¸íŠ¸ì˜ í›ˆë ¨ ë ˆì´ë¸”ì—ëŠ” 0ë¶€í„° 9ê¹Œì§€ì˜ 10ê°€ì§€ ê³ ìœ í•œ ê°’ì´ ìˆìœ¼ë©°, ê° ê°’ì— 6000ê°œì˜ ë ˆì´ë¸”ì´ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¦‰, ê° ì˜ë¥˜ ìœ í˜•ì—ëŠ” 6000ê°œì˜ ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤.

ê²°ê³¼ê°’ í•´ì„

ì²« ë²ˆì§¸ ë°°ì—´ì€ ê³ ìœ í•œ ê°’ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
ë‘ ë²ˆì§¸ ë°°ì—´ì€ ê° ê³ ìœ í•œ ê°’ì— ëŒ€í•œ ê°œìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
ì´ ê²°ê³¼ê°’ì€ Fashion-MNIST ë°ì´í„° ì„¸íŠ¸ì˜ ê· í˜• ì¡íŒ ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì˜ë¥˜ ìœ í˜•ì—ëŠ” ë™ì¼í•œ ìˆ˜ì˜ ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤.

ì¶”ê°€ì ì¸ ì£¼ì„ìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì´ ìˆìŠµë‹ˆë‹¤.

np.unique() í•¨ìˆ˜ëŠ” ë°ì´í„° ì„¸íŠ¸ì˜ ë ˆì´ë¸”ì„ ì •ë¦¬í•˜ëŠ” ë° ìœ ìš©í•œ ë„êµ¬ì…ë‹ˆë‹¤.
return_counts=True ë§¤ê°œë³€ìˆ˜ëŠ” ë°ì´í„° ì„¸íŠ¸ì˜ ê· í˜• ì¡íŒ ë¶„í¬ë¥¼ í™•ì¸í•˜ëŠ” ë° ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

import numpy as np

print(np.unique(train_target, return_counts=True))

## ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ íŒ¨ì…˜ ì•„ì´í…œ ë¶„ë¥˜í•˜ê¸°

train_scaled = train_input / 255.0
train_scaled = train_scaled.reshape(-1, 28*28)

print(train_scaled.shape)

from sklearn.model_selection import cross_validate
from sklearn.linear_model import SGDClassifier

sc = SGDClassifier(loss='log', max_iter=5, random_state=42)

scores = cross_validate(sc, train_scaled, train_target, n_jobs=-1)
print(np.mean(scores['test_score']))

## í…ì„œí”Œë¡œì™€ ì¼€ë¼ìŠ¤

import tensorflow as tf
from tensorflow import keras

## ì¸ê³µì‹ ê²½ë§ìœ¼ë¡œ ëª¨ë¸ ë§Œë“¤ê¸°

from sklearn.model_selection import train_test_split

train_scaled, val_scaled, train_target, val_target = train_test_split(
    train_scaled, train_target, test_size=0.2, random_state=42
)

print(train_scaled.shape, train_target.shape)

print(val_scaled.shape, val_target.shape)

dense = keras.layers.Dense(10, activation='softmax', input_shape=(784,))

model = keras.Sequential(dense)

## ì¸ê³µì‹ ê²½ë§ìœ¼ë¡œ íŒ¨ì…˜ ì•„ì´í…œ ë¶„ë¥˜í•˜ê¸°

model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')


print(train_target[:10])

model.fit(train_scaled, train_target, epochs=5)

model.evaluate(val_scaled, val_target)
```






  ë³¸ í›„ê¸°ëŠ” ì •ë³´í†µì‹ ì‚°ì—…ì§„í¥ì›(NIPA)ì—ì„œ ì£¼ê´€í•˜ëŠ” <AI ì„œë¹„ìŠ¤ ì™„ì„±! AI+ì›¹ê°œë°œ ì·¨ì—…ìº í”„ - í”„ë¡ íŠ¸ì—”ë“œ&ë°±ì—”ë“œ> ê³¼ì • í•™ìŠµ/í”„ë¡œì íŠ¸/ê³¼ì œ ê¸°ë¡ìœ¼ë¡œ ì‘ì„± ë˜ì—ˆìŠµë‹ˆë‹¤. #ì •ë³´í†µì‹ ì‚°ì—…ì§„í¥ì› #NIPA #AIêµìœ¡ #í”„ë¡œì íŠ¸ #ìœ ë°ë¯¸ #ITê°œë°œìº í”„ #ê°œë°œìë¶€íŠ¸ìº í”„ #í”„ë¡ íŠ¸ì—”ë“œ #ë°±ì—”ë“œ #AIì›¹ê°œë°œì·¨ì—…ìº í”„ #ì·¨ì—…ìº í”„ #ê°œë°œì·¨ì—…ìº í”„   
