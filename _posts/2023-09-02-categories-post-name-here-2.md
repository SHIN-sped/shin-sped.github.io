---
title: "[NIPA]AI+웹개발 취업캠프 SW심화 7주차 6회"
excerpt: "위클리 학습일지"

categories:
  - Categories2
tags:
  - [정보통신산업진흥원, NIPA, AI교육, 프로젝트, 유데미, IT개발캠프, 개발자부트캠프, 프론트엔드, 백엔드, AI웹개발취업캠프, 취업캠프, 개발취업캠프]

permalink: /categories2/post-name-here-21/

toc: true
toc_sticky: true

date: 2023-09-02
last_modified_at: 2023-09-02
---

## 🦥 인공지능 AI 능력시험 AICE Basic 2/2 



## AICE PROCESS

### 1)문제 정의 - 목적과 목표를 명확히 하는 단계

#### AI를 적용하여 해결하기에 적절한 문제인가?

#### 어떤 경우에 AI를 적용하면 효과적인가?

 #### 학습 목표

#### 1.AI가 적용될수 있는 상황 - 01.데이터나 규칙이 복잡한 경우

전통적인 프로그래밍 환경 - 너무 많은 데이터, 많아지는 규칙들, 복잡해지는 프로그래밍 규칙

데이터나 규칙이 복잡한 경우 - 시간 지연, 오류 발생

AI활용으로 데이터 기반으로 스스로 학습, 자동으로 규칙 생성 -> 데이터 규칙이 복잡한 경우에 효율적인 AI



#### 1.AI가 적용될수 있는 상황 - 02.다양한 형태의 데이터를 활용하는 경우

구조 관점의 데이터 구분 - 정형 데이터, 반정형 데이터, 비정형 데이터

| 유형                            | 설명                                       | 종류                      |
| ----------------------------- | ---------------------------------------- | ----------------------- |
| 정형데이터(Structured Data)        | 행(row)과 열(Column)의 정형화된 구조 기반으로 고정된 필드에 저장되며  값과 형식이 일관됨 | 관계형 데이터베이스(RDBMS), 엑셀 등 |
| 반정형 데이터(Semi-structured Data) | 구조와 형태를 가지나, 값과 형식에 일관성을 갖고 있지 않음        | 로그, 스크립트 등              |
| 비정형 데이터(Unstructured Data)    | 구조와 형태가 정해지지 않으며 고정된 필드에 저장되지 않음         | 텍스트, 이미지, 오디오, 비디오 등    |

과거에 잘 활용되지 못했던 반정형 비정형 데이터

데이터 저장방식의 발전과 알고리즘 및 학습 방식 연구로 반정형 비정형 데이터의 비약적인 발전

텍스트 데이터 - 형태소 기반 특성 학습

이미지 데이터 - 사이즈 필터 특성 학습

딥러닝의 인공신경망을 활용한 모델의 발전 기반



#### 1.AI가 적용될수 있는 상황 - 03.미지의 영역에 대한 연구와 해결이 필요한 경우

지도 학습 - 과거 데이터를 기반으로 미래 상황을 예측

비지도 학습 - 수집된 데이터 사이에서 숨겨진 특성 발견

강화 학습 - 사람이 예상하지 못하는 방식으로 해법 발견

규칙을 찾아내는 AI의 능력으로 미지의 영역 개척에 효율적인 AI



#### 2.AI의 5가지 주요 기능 - AI로 해결할 수 있는 비즈니스 문제를 해결 가능

비즈니스 문제를 정의할 수 없다면? AI가 적합한 해결책인지 고민이 필요

예측(Prediction)

* 용도 - 데이터 학습, 패턴 파악으로 결과를 예측
* 종류 - 귀추 예측, 선호 예측, 맥락 예측

생성(Generation)

* 용도 - 텍스트, 음성, 사진, 동영상 등을 생성
* 종류 - 심미적 생성, 실용적 생성

소통(Conversation)

* 용도 - 기계에 대한 기능을 부여하여, 답변과 질문을 다양하게 연출
* 종류 - 응대, 대화

자동화(Automation)

* 용도 - 사람에 의지하지 않고, 더 효율적인 방법을 찾아 최적화ㅣ
* 종류 - 자동 처리, 자동 최적화, 의사결정 자동화

인식(Recognition)

* 용도 - 대상의 다양한 특성을 인지하고 상황을 판단
* 종류 - 이미지 인식, 음성 인식, 감정 인식, 맥락 인식

### 데이터 수집 - 가능한 많고, 깨끗한 데이터

문제 정의 이후 수행

데이터를 수집하는 절차는?

내가 어떤 데이터를 필요로 하는가?

필요 데이터 정의, 구체적 획득 방안 수립 -> AI 구현 프로세스 전반의 반복과 지연 방지



#### 수집할 데이터의 종류

* 내부 데이터 - 내 업무 영역 안에서 쉽게 구할 수 있는 데이터

* 외부 데이터 - 내 업무 영역 밖으로 연계되는 데이터

  | 유형    | 설명                                       | 종류                                    |
  | ----- | ---------------------------------------- | ------------------------------------- |
  | 내부데이터 | 1.동일한 시스템계 및 업무 영역 내부에 위치한 데이터<br />2.데이터 수명주기 관리가 용이<br />3.민감 정보가 포함되어 있을 수 있음 | 서비스(인증, 거래 등)<br />네트워크(방화벽, 시스템 등)   |
  | 외부데이터 | 1.외부 시스템 업무 영역에 위치한 데이터<br />2.데이터 구매 혹은 수집 절차 고려 필요<br />3.공개된 데이터 | 소셜(SNS, 커뮤니티 등)<br />공공(의료,지역,기상정보 등) |

  ​

#### 데이터 수집 방식 - 크롤링(Crawling), RSS(Rich Site Summary), Open API, 스트리밍(Streaming)

* 내무 데이터 - 이미 보유 중, 담당자와의 협의로 획득 가능

* 외부 데이터 - 별도의 수집 방법 활용 필요

* 크롤링(Crawling) - 다양한 웹 문서 및 콘텐츠를 수집하는 방식 ex)'AI'관련 키워드가 포함된 최근 일주일 이내 뉴스 기사의 제목, 내용

* RSS(Rich Site Summary) - 웹 사이트에 게시된 새로운 글을 공유하는 프로토콜 활용 수집 ex)관심있즌 블로그들의 RSS피드를 모두 수집해서 한 눈에 볼 수 있도록 구성

* Open API - 응용 프로그램을 통한 실시간 데이터 수신 -> 공개 API를 이용하여 데이터 수집, 데이터포털(data.go.kr)에서 미세먼지 정보를 API로 수집

* 스트리밍(Streaming) - 네트워크를 통한 미디어 데이터의 실시간 수집 ex)행사 영상을 유튜브를 통해 실시간 스트리밍

  ​

#### 편향과 결측치에 대한 이해

#### AI가 학습가능한 데이터로 활용하려면? - 1)분석 목적에 부합 2)대표성을 가진 데이터 3)충분히 많고 깨끗한 데이터 수집

#### 깨끗한 데이터란? - 편향(bias)되지 않은 데이터, 결측치(Missing Values)가 없는 데이터

#### 데이터가 편향되었거나 손실되었다면? - AI는 정확하지 않은 학습을 하게됨

#### 정확한 AI 학습 포인트 - 충분히 많고 깔끔한 이터를 수집하기

#### 데이터의 손실이 있으면 정확하지 않은 학습이 이루어질 수 있습니다

| 유지여부  | 계약건수 | 고객등급통합코드 | VIP관리태그 통합코드 | VVIP 고객여부 |
| ----- | ---- | -------- | ------------ | --------- |
| **Y** | 8    | L        | -            | N         |
| **Y** | 3    | L        | **BM**       | Y         |
| **Y** | 3    | L        | **BM**       | Y         |
| **Y** | 3    | L        | -            | N         |
| **Y** | 6    | L        | -            | N         |

Table 유지여부 - 불균형 발생, 편향된 데이터 수집, 학습을 시키더라도 예측 대상인 N 도출 불가, 어떤 조건을 넣더라도 Y라는 결과만 도출

Table VIP관리태그 통합코드 - AI를 통한 데이터 학습시 없는 특성값(FEATURE)을 기계가 판단할 수는 없음, 입력된 값을 기반으로 편향된 결과 도출 우려

* 데이터 편향 - 수집된 데이터의 불균형이 일어나 특정 값으로 치우친 것
* 데이터 결측치 - 손실되고 비어있는 값

### 데이터 분석 및 전처리 - 중요한 데이터를 찾고, 사전 준비, EDA를 통한 데이터 분석 후 데이터 전처리

#### 데이터 분석 - 어떤 데이터가 중요한 특성을 가지는지 찾는 과정

#### 데이터 전처리 - 데이터를 어떻게 AI 학습에 활용할지 준비하는 단계

#### 탐색적 데이터 분석EDA(Exploratory Data Analysis)

#### 주요 단계별로 중요 개념 알아보기

#### 데이터 타입 확인 - 수치형(Numerical), 문자형(Object or String), 범주형(Categorical), 불리언형(Boolean) 

수치형(Numerical)

* 연속형 - 틈새가 없이 연속되는 값, 키, 몸무게, 시간
* 이산형 - 셀수 있는 값, 사람 수, 판매수량

문자형(Object or String)

* 문자로만 이루어진 타입
* '문자+숫자'로 구성된 타입

범주형(Categorical)

* 범주를 나눌 수 있는 데이터, 사칙연산 불가능, 숫자로 이루어진 범주형 데이터
* 순서형(Ordinal) - 순서(대소)를 매길 수 있음, 학점
* 명목형(Nominal) - 순서를 매길 수 없음, 성별, 5지선다 선택지

불리언형(Boolean)

* 참(True) 거짓(False) 둘 중 하나만 가질 수 있는 데이터 타입

  ​

#### 기술통계 - 통계적인 방법을 활용해 수집한 데이터를 요약 묘사 설명하는 기법

#### 기술 통계 확인 - Technology? 복잡하고 어려운 개념?

#### 기술 통계에서 다루는 개념들?

#### 각 통계량의 시각화 및 데이터 활용 용법은?



#### 데이터가 어떻게 '모여'있는지를 표현하는 통계량 - 개수(Counts), 평균값(Mean), 중앙값(Median), 최빈값(Mode)

* 개수(Counts) - 데이터의 개수
* 평균값(Mean) - 산술평균, 각 데이터를 모두 더한 후 데이터의 개수로 나눈 값
* 중앙값(Median) - 데이터를 크기 순서대로 배열했을 때 중앙에 위치하는 값
* 최빈값(Mode) - 데이터 중에서 빈도수가 가장 높은 값

#### 데이터가 어떻게 '흩어져'있는지를 표현하는 통계량 - 최솟값(Minimum), 최댓값(Maximum), 분산(Variance), 표준편차(Standard Deviation), 사분위수(Quartile), 첨도(Kurtosis), 왜도(Skewness)

* 최솟값(Minimum) - 데이터 중에서 가장 작은 값
* 최댓값(Maximum) - 데이터 중에서 가장 큰 값
* 분산(Variance) - 데이터가 평균으로부터 떨어진 정도, 차이값의 제곱의 평균
* 표준편차(Standard Deviation) - 데이터가 평균으로부터 떨어진 정도, 분산의 제곱근
* 사분위수(Quartile) - 모든 데이터를 순서대로 배열 시, 4등분한 지점에 있는 값
* 첨도(Kurtosis) - 데이터의 분포가 정규분포 대비 뾰족한 정도를 나타내는 값, 양수(오름), 음수(내림)
* 왜도(Skewness) - 데이터의 분포가 정규분포 대비 비대칭한 정도를 나타내는 값, 양수(왼쪽), 음수(오른쪽)

| 구분   | 설명   |                             | 예          |
| ---- | ---- | --------------------------- | ---------- |
| 수치형  | 연속형  | 값 간에 틈새가 없이 연속되는 데이터        | 키, 시간      |
|      | 이산형  | 셀 수 있는 값으로 표현되는 데이터         | 사람 수, 물건 수 |
| 문자형  |      | 문자로만 이루어지거나 문자와 숫자로 구성된 데이터 | 로그인 ID     |
| 범주형  | 순서형  | 범주로 구분되며, 순서를 매길 수 있는 데이터   | 학점         |
|      | 명목형  | 범주로 구분되며, 순서를 매길 수 없는 데이터   | 남녀         |
| 불리언형 |      | 논리 값인 참과 거짓 중 하나로 표현되는 데이터  | 참, 거짓      |



### 데이터 시각화 - 데이터 분석 결과를 시각적 표현 전달하는 과정

#### 숫자 데이터, 문자 데이터, 데이터 간의 관계를 쉽게 파악하기 어려움

#### 대표 시각화 기법 - 히스토그램(Histogram), 분포차트(Density Plot), 박스차트(Boxplot), 카운트플롯(Countplot), 산점도(Scatterplot), 히트맵(Heatmap)

#### 히스토그램과 카운트플롯의 차이점은? - 카운트플롯은 수치형 데이터가 아닌 범주형 데이터를 활용

* 히스토그램(Histogram) - 수치형 데이터의 구간별 빈도수를 나타내는 시각화 기법, 가장 기본적으로 활용되는 시각화 기법, 숫자 5만큼의 구간으로 나누어 탑승자 빈도수 표현 1)데이터 집합의 중심 2)값의 분포 및 형태
* 분포차트(Density Plot) - 수치형 데이터의 구간별 빈도수를 나타내는 시각화 기법, 색상(Hue)으로 범주형 데이터 속성 반영: 해당 구간 내에서의 빈도를 보여줌, '생존여부' 데이터 속성을 색상(Hue)으로 추가: 붉은색 생존자 분포를 확인 가능, 분포의 X축 양쪽(생존자와 사망자)
* 박스차트(Boxplot) - 수치형 데이터 통계정보를 기반으로 그 분포를 박스 모양으로 나타낸 시각화 기법, 통계적 특성을 한 눈에 파악 가능 1)데이터 분포 2)이상치, x sex y age
   * 최솟값(Minimum) - 해당 범주 내 데이터 중 가장 작은 값 ex)0.3333
   * 하위 장벽(Lower Fence) - 박스 바깥의 하단에 위치한 선으로 통계적으로 Q1 - (1.5 * IQR)의 위치, 21 - (1.5 * 18) = -6=최솟값
   * Q1, 1사 분위수 - 박스 하단의 선으로, 데이터 분포 상 25% 수준에 위치 ex) 21
   * 중앙값(Median), 2사 분위수 - 박스 중간의 선으로, 데이터 분포 중 50% 수준에 위치, 산술적으로 계산되는 평균(Mean)과는 다른 값임을 주의 ex)28
   * Q3, 3사 분위수 - 박스 상단의 선으로, 데이터 분포 중 75% 수준에 위치 ex)39
   * 상위 장벽(Upper Fence) - 박스 바깥의 상단에 위치한 선으로, 통계적으로 Q3 + (1.5 * IQR)의 위치, 39 + (1.5 * 18) = 66
   * 최댓값(Maximum) - 해당 범주 내 데이터 중 가장 큰 값, ex)80
   * IQR(InterQuartile Range) - Q1과 Q3 사이의 거리, Q3 - Q1 = 39 - 21 = 18
   * 이상치 - 통계적으로 하위 장벽돠 상위 장벽을 벗어나는 값으로, 점으로 표현됨
* 카운트플롯(Countplot) - 범주형 데이터에 대한 값의 개수를 보여주는 시각화 기법, x축 value, y축 index
* 산점도(Scatterplot) - 두 수치형 데이터 사이의 관계를 보여주는 시각화 기법, 수치를 좌표평면 상의 점으로 표시, 회귀선을 그어 상관관계 확인
* 산점도 ex)보스턴 부동산 부지 면적과 판매 가격의 관계 - 부지 면적이 넓을수록 판매 가격도 높아지는 상관관계
* 히트맵(Heatmap) - 두 수치형 데이터 사이의 관계 표현, 색상 활용, 데이터 간 상관관계 표현, 색상 활용 데이터 간 상관관계 표현, 구현 환경에 따라 색상 변화, 색인을 참고하여 히트맵 해석, 상관계수(Correlation), 상관계수(Correlation) -1(음의 상관관계) 0(상관관계 없음) 1(양의 상관관계, 자신과의 상관관계), 색의 음영으로 시각화, 절대값 0.7이상 : 강한 상관관계, 절대적 해석 기준 없음, 주관적 판단 가능

| 구분         | 시각화 도구 | 설명                                       | 예                       |
| ---------- | ------ | ---------------------------------------- | ----------------------- |
| 데이터 자체 분석  | 히스토그램  | 수치형 데이터의 구간별 빈도수를 나타냄                    | 연령 구간별 참석자 수            |
|            | 분포차트   | 수치형 데이터의 구간별 빈도수와 함께 범주형 데이터의 클래스별 분포를 색상으로 나타냄 | 연령 구간별 참석자 수와 성별에 따른 분포 |
|            | 박스차트   | 수치형 데이터의 통계정보(최솟값, 제1사분위, 제2사분위, 제3사분위, 최댓값을 박스모양으로 나타냄 ) | 서울지역 편의점들의 연관 매출 통계 분포  |
|            | 카운트플롯  | 범주형 데이터의 클래스별 개수를 나타냄                    | 지하철 역별 일일 승객수           |
| 데이터간 관계 분석 | 산점도    | 수치형 데이터 간의 관계를 점으로 표현함                   | 한 학급 내 학생들의 키와 몸무게      |
|            | 히트맵    | 수치형 데이터 간의 상관관계를 색상으로 표현함                | 미세먼지 수치와 기온과의 상관관계      |



#### 데이터 형태 파악 및 시각화 진행 과정

#### 데이터에 결측치가 포함된 경우? - 후속 데이터 분석 및 AI 모델링 진행 불가 => 추가적 조사 및 정확한 예측을 통한 처리 필요

#### 결측치 처리 - 제거(Drop), 대체(Fill)

* 제거(Drop) - 데이터가 충분히 많은 경우, 결측치가 영향을 미치지 않는 경우 -> 결측치를 제거하는 것이 효과적, ex)Row단위 Drop Column단위 Drop

* 제거(Drop) - Drop하기 전 주의사항 정보가 반드시 손실될 수 밖에 없음 -> 비즈니스 관점 영향도를 신중하게 고려 후 결정

* 대체(Fill) - 데이터가 충분하지 않은 경우, 결측치를 채워 모든 데이터를 AI가 학습하도록 도움, 결측치의 특성이 무작위로 관찰되지 않음 => 상관관계 예측모델 사용, 예측값으로 대체

* 대체(Fill) 장점 - 정보 손실이 없이 빠르게 채울 수 있음

* 대체(Fill) 유의점 - 채워진 값에 의해 전체 데이터의 통계량 및 상관관계 영향

* 결측치 대체 방법 - 평균값/중앙값, 예측값, 최빈값, 유사벡터값 ex)평균값(Mean), 중앙값(Median)으로 대체값 적용, 최빈값(Mode)으로 대체값 적용, 유사벡터값으로 대체값 적용 ex(Col1, Col4 값이 같으므로 적용), 선형회귀 예측값

  ​

#### 이상치 처리 - 전체 데이터의 추세/패턴 등에서 벗어난 값을 가진 데이터

#### 데이터에 이상치 존재 -> 추세/패턴을 벗어나는 데이터에도 반영 -> 모델 성능에 좋지 않은 영향

#### 이상치를 찾고 처리하는 방법은?

#### 이상치(Outlier) 탐지 방법 

* IQR(InterQuartile Range) 값 활용하기, 통계적으로 이상치의 범위를 IQR를 활용해서 계산, 일반적으로 많이 사용하는 값이며, 절대적이지 않음, 1.5보다 크거나 작은 값을 선택할 수 있음 IQR 기법 이외의 이상치를 정의하는 다른 기준을 적용 가능
* 박스차트로 이상치를 시각적으로 쉽게 확인 가능

#### 이상치 처리 시 주의해야 할 점은?

* 타겟 변수가 분류 모델일 경우 - 카테고리 별 박스 차트 그리기 => 타겟 변수의 카테고리에 이상치 분포 확인하기
* 분포에 따라서 '의미가 있는 이상치'가 될 수 있음 => 함부로 제거하면 안 됨
* 의미가 있는 이상치 - 이상치가 타겟 변수(A, B)의 카테고리 별로 유사한 비중으로 들어가 있음, 특정 카테고리 값(A)으로만 구성되어 있음



#### 모든 컬럼에 대해서 IQR을 계산해보거나 박스차트를 그려야 할까? 

* 컬럼이 너무 많으면 모든 컬럼을 다 확인하기 어려움
* 평균값(mean)과 중앙값(median)이 차이가 나는 컬럼 확인
* 평균과 중앙값 대비 최소 최댓값이 차이가 나는 컬럼 확인



#### 이상치 처리 방법

* 적당한 스케일링 기법을 적용하여 그대로 사용
* 이상치 포함 행 삭제
* 이상치 경계값 치환 - Q3+IQR*1.5 Q1-IQR**1.5
* 이상치가 경계 근처에 몰린 경우 - 적당한 스케일링 기법을 적용하여 그대로 사용
* 이상치가 포함한 행의 개수가 적음 - 이상치 포함 행 삭제
* 이상치를 포함한 행의 개수가 많음 - 이상치 경계 치환
* 1)이상치 탐지(IQR) - 타겟 변수가 카테고리라면 카테고리별 이상치 구분
* 2)이상치 처리 - 행 삭제, 다른 값으로 치환, 그대로 놔두기



#### 결측치 처리

* 1)실무자 견해가 많이 반영되는 단계 - 분석 방향에 따라 결과에 차이
* 2)많은 시간이 투자되어야 함
* 3)데이터 현실을 반영한 처리 - 정확한 분석과 모델링 가능
* 제거(Drop) - 가장 쉽게 처리할 수 있는 방법, 막대한 데이터 손실 동반
* 대체(Fill) - 단순 대체할 경우, 전체적 통계 값에 영향
* 0은 결측치가 아닙니다 -> 결측치는 NaN으로 표현

#### 알 수 없는 값을 '0'으로 입력하도록 정의한 경우에는? - 0을 결측치로 간주,  제거 대체 처리 필요

#### 데이터 분포를 기준으로 상/하단의 이상치 판단 방법 - 1, 3사분위수와 IQR 활용

* 상단 이상치 - 데이터 값 > Q3+IQR*1.5
* 하단 이상치 - 데이터 값 < Q1-IQR*1.5



#### 인코딩

* 문자데이터 -> 인코딩(Encoding) => 숫자 데이터
* 데이터 간 순서 여부에 따른 분류, 카테고리 순서 여부에 따른 선택 - Ordinal Encoding, One-Hot Encoding
* Ordinal Encoding - 데이터 간 순서가 있는 카테고리 데이터
* One-Hot Encoding - 카테고리 수만큼 0과 1로만 구성된 새로운 컬럼을 만들어 맵핑, 데이터 간 순서가 없는 카테고리 데이터

| No   | Class       |
| ---- | ----------- |
| 0    | Business->0 |
| 1    | Eco->1      |
| 2    | Eco Plus->2 |
| 3    | Eco         |
| 4    | Business    |



Ordinal Encoding

| No   | Class       |
| ---- | ----------- |
| 0    | 0-> 1, 0, 0 |
| 1    | 1-> 0, 1, 1 |
| 2    | 2-> 0, 0, 0 |
| 3    | 1-> 0, 1, 1 |
| 4    | 0-> 1, 0, 0 |

One-Hot Encoding

| No   | Class_Business | Class_Eco | Class_Eco Plus |
| ---- | -------------- | --------- | -------------- |
| 0    | 1              | 0         | 0              |
| 1    | 0              | 1         | 0              |
| 2    | 0              | 0         | 1              |
| 3    | 0              | 1         | 0              |
| 4    | 1              | 0         | 0              |

#### 데이터의 카테고리에 맞는 컬럼에만 1, 나머지는 0을 채워 넣는 방식 -> 복잡성 이해하기

#### 각 인코딩 방식은 어떤 데이터에 적용해야 하는가? - 분석가 개인적인 해석에 따라서 적용할 인코딩 종류에 차이 발생



#### 스케일링

* 수치형 데이터에 사용
* 변수간 비교를 위해 수치 단위를 맞추려고 수치의 크기 변경
* 수치의 크기를 유사하기 맞춰주는 스케일링 기법

#### 스케일링 과정이 필요한 이유는? - AI가 학습을 할 때 모든 정보를 숫자로 판단하기 때문

| No   | Col1 | Col2 | Col3   |
| ---- | ---- | ---- | ------ |
| 0    | 1    | 2    | 15,000 |
| 1    | 0    | 1    | 20,000 |
| 2    | 0    | 2    | 25,000 |
| 3    | 0    | 0    | 30,000 |
| 4    | 1    | 0    | 40,000 |

#### 트리 기반 알고리즘 - 스케일에 따른 영향을 거의 받지 않는 알고리즘, 그렇지 않은 알고리즘도 많으므로 스케일링도 전처리 할 때 유의!



#### 주식 데이터(A주식)

| 날짜         | 거래량         | 종가    | 환율    |
| ---------- | ----------- | ----- | ----- |
| 2021-02-01 | 310,002,000 | 5,600 | 1,090 |
| 2021-02-02 | 289,300,000 | 5,700 | 1,120 |
| 2021-02-03 | 320,040,000 | 5,900 | 1,130 |
| 2021-02-04 | 330,300,000 | 6,100 | 1,100 |
| 2021-02-05 | 310,001,000 | 5,950 | 1,140 |

#### 거래량 수치가 크다고, 조가보다 중요 정보는 아니죠 => 사람은 '거래량'과 '종가'컬럼이 서로 다른 종류의 정보임을 인식 가능

#### 거래량에 더 많은 가중치, 거래량이 더 중요한 데이터 => AI는 '거래량'과 '종가'컬럼이 서로 다른 정보라는 개념이 없음



#### 대표적인 스케일링 기법

* Min-Max Scaling - 해당 컬럼의 최솟값(Min)과 최댓값(Max) 이용, 모든 데이터를 0-1사이로 맞추기, (Data-Min) / (Max-Min), 해당 컬럼의 최솟값(Min)과 최댓값(Max) 이용하여 이상치에 직접적인 영향
* Standard Scaling - 해당 컬럼의 평균(Mean)과 표준편차(std) 이용, 평균은 0 표준편차는 1로 맞추기, (Data-Mean)/ (std), - + 값으로 표시됨, 평균값에 의해 이상치에 간접적인 영향
* 이상치가 없거나, 박스 차트 상/하단 경계 근처에 있음, 개인적 해석으로 선택 가능
* 스케일링 후 컬럼 별로 데이터 범위가 비슷해졌음
* 경계를 벗어난 이상치가 있다면 주의 필요 -> 이상치에 많은 영향을 받음, Standard Scaling(상대적으로 이상치에 덜 영향)
* 이상치로 인해서 스케일링이 잘 되지 않음, 1 또는 0에 데이터가 몰려 있음
* 주식데이터에서 종가와 환율 컬럼 - 스케일링이 잘 되지 않음
* 주식데이터에서 거래량 컬럼 - 중간값과 평균값 차이가 적어 스케일링이 되었음

#### 이상치 영향을 받지 않는 중간값 평균값이 유사하다? -> 이상치가 있어도 스케일링에 끼치는 영향을 적음

#### 데이터 이상치가 존재하고 둘 주에서 골라야 한다면? -> Min-Max Scaling, Standard Scaling

#### 컬럼 간 스케일 차이로 잘못된 판단을 할 여지가 있어 스케일링 적용 -> Min-Max Scaling, Standard Scaling





### AI 모델링 - 학습기법을 선택하고 모델을 생성/평가

#### AI 모델링이란? - 데이터에 적합한 AI 알고리즘 선택, 준비된 데이터로 모델 학습, 평가 및 개선

#### 모델 선택 및 학습 - 알고리즘의 선택

#### 모델 선택 및 학습 - 모델 학습

#### 어떤 AI 알고리즘이 데이터와 과제의 목적에 적합할까? - 설명, 예측

* 설명 - 결과의 원인 분석, 결과에 영향을 주는 변수(컬럼) 분석
* 예측 - 결과 자체가ㅏ 중요한 경우, 미래 상황에 대비하고 정확히 알아야 하는 경우

#### A카페 사장님의 전략 -> AI과제 수행 -> 다음주에 팔릴 커피 수량 체크 -> 미리 적당량의 원두 구매252





#### 알고리즘 선택

* 지도 학습(Supervised Learning) - 타겟 변수(분류를 위한 데이터, 수치 예측(회귀)를 위한 데이터) Linear Regression(수치 예측을 위한 알고리즘)







### AI 적용 - 만든 모델을 시스템화 하고 유지보수



- ​


  본 후기는 정보통신산업진흥원(NIPA)에서 주관하는 <AI 서비스 완성! AI+웹개발 취업캠프 - 프론트엔드&백엔드> 과정 학습/프로젝트/과제 기록으로 작성 되었습니다. #정보통신산업진흥원 #NIPA #AI교육 #프로젝트 #유데미 #IT개발캠프 #개발자부트캠프 #프론트엔드 #백엔드 #AI웹개발취업캠프 #취업캠프 #개발취업캠프   
