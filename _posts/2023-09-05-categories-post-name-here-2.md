---
 title: "[NIPA]AI+ì›¹ê°œë°œ ì·¨ì—…ìº í”„ SWì‹¬í™” 8ì£¼ì°¨ 2íšŒ"
excerpt: "ë°ì¼ë¦¬ í•™ìŠµì¼ì§€"

categories:
  - Categories2
tags:
  - [ì •ë³´í†µì‹ ì‚°ì—…ì§„í¥ì›, NIPA, AIêµìœ¡, í”„ë¡œì íŠ¸, ìœ ë°ë¯¸, ITê°œë°œìº í”„, ê°œë°œìë¶€íŠ¸ìº í”„, í”„ë¡ íŠ¸ì—”ë“œ, ë°±ì—”ë“œ, AIì›¹ê°œë°œì·¨ì—…ìº í”„, ì·¨ì—…ìº í”„, ê°œë°œì·¨ì—…ìº í”„]

permalink: /categories2/post-name-here-23/

toc: true
toc_sticky: true

date: 2023-09-05
last_modified_at: 2023-09-05
---

## ğŸ¦¥ ë³¸ë¬¸


## ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ ì™€ì¸ ë¶„ë¥˜í•˜ê¸°

```python
import pandas as pd

wine = pd.read_csv('https://bit.ly/wine-date')

wine.head()

wine.info()

wine.describe()


data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()



from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(
    data, target, test_size=0.2, random_state=42)

print(train_input.shape, test_input.shape)



from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(train_input)

train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)


from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(train_scaled, train_target)

print(lr.score(train_scaled, train_target))
print(lr.score(test_scaled, test_target))
```

## ì„¤ëª…í•˜ê¸° ì‰¬ìš´ ëª¨ë¸ê³¼ ì–´ë ¤ìš´ ëª¨ë¸

```python
print(lr.coef_, lr.intercept_)

# ê²°ì •íŠ¸ë¦¬
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)
dt.fit(train_scaled, train_target)

print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))


import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(10,7))
plot_tree(dt)
plt.show()


plt.figure(figsize=(10,7))
plot_tree(dt, max_depth=1, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()


# ê°€ì§€ì¹˜ê¸°

dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_scaled, train_target)

print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))


plt.figure(figsize=(20,15))
plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()

dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_input, train_target)

print(dt.score(train_input, train_target))
print(dt.score(test_input, test_target))



plt.figure(figsize=(20,15))
plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()

print(dt.feature_importances_)


# í™•ì¸ë¬¸ì œ
dt = DecisionTreeClassifier(min_impurity_decrease=0.0005, random_state=42)
dt.fit(train_input, train_target)

print(dt.score(train_input, train_target))
print(dt.score(test_input, test_target))

plt.figure(figsize=(20,15), dpi=300)
plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()

```





  ë³¸ í›„ê¸°ëŠ” ì •ë³´í†µì‹ ì‚°ì—…ì§„í¥ì›(NIPA)ì—ì„œ ì£¼ê´€í•˜ëŠ” <AI ì„œë¹„ìŠ¤ ì™„ì„±! AI+ì›¹ê°œë°œ ì·¨ì—…ìº í”„ - í”„ë¡ íŠ¸ì—”ë“œ&ë°±ì—”ë“œ> ê³¼ì • í•™ìŠµ/í”„ë¡œì íŠ¸/ê³¼ì œ ê¸°ë¡ìœ¼ë¡œ ì‘ì„± ë˜ì—ˆìŠµë‹ˆë‹¤. #ì •ë³´í†µì‹ ì‚°ì—…ì§„í¥ì› #NIPA #AIêµìœ¡ #í”„ë¡œì íŠ¸ #ìœ ë°ë¯¸ #ITê°œë°œìº í”„ #ê°œë°œìë¶€íŠ¸ìº í”„ #í”„ë¡ íŠ¸ì—”ë“œ #ë°±ì—”ë“œ #AIì›¹ê°œë°œì·¨ì—…ìº í”„ #ì·¨ì—…ìº í”„ #ê°œë°œì·¨ì—…ìº í”„   
